<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tleukhan's Webpage</title>
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;600;700&display=swap" rel="stylesheet">
</head>
<body>

<!-- Navigation Bar -->
<nav class="navbar">
    <div class="container">
        <div class="logo">Tleukhan Mussin</div>
        <div class="menu">
            <a href="index.html">Home</a>
            <a href="cv.html">CV</a>
            <a href="projects.html" class="active">Projects</a> <!-- Active state for Projects page -->
            <a href="publications.html">Publications</a>
            <a href="contact.html">Contact</a>
        </div>
    </div>
</nav>

<!-- Project Details Section -->
<div class="project-details container">
    <h1>NUSense: Robust Soft Optical Tactile Sensor</h1>

    <!-- Links to GitHub and Publication -->
    <div class="project-links">
        <a href="https://github.com/yourusername/project-repo" target="_blank" class="link-button">
            View on GitHub
        </a>
        <a href="https://yourpublicationlink.com" target="_blank" class="link-button">
            View Publication
        </a>
    </div>
     
    <!-- New Image Container -->
     <img src="project2/fig1_hope.png" alt="Event-based Agile Object Catching" class="project2-details-image">

    <p class="project-date">Project Date: May, 2024</p>

    <p>
        In this project, we explore the use of event-based cameras to improve the performance of high-speed catching tasks with quadrupedal robots. 
        Event-based cameras are specialized sensors that capture changes in the scene asynchronously, enabling faster response times and lower 
        latency compared to traditional frame-based cameras.
    </p>

    <p>
        The main goal of this project is to design a control system for a quadrupedal robot that can detect and catch high-speed objects 
        traveling at up to 15 m/s. By leveraging the advantages of event-based vision, the robot can process visual data more efficiently, 
        making it better suited for real-time dynamic interactions in complex environments.
    </p>

    <p>
        The outcomes of this project demonstrate significant improvements in the reaction speed and accuracy of robotic systems in fast-paced 
        scenarios, paving the way for more agile and efficient robotic solutions in industries such as manufacturing, logistics, and search-and-rescue operations.
    </p>

    <h2>Technologies Used</h2>
    <ul>
        <li>Event-based Vision Sensors</li>
        <li>ROS (Robot Operating System)</li>
        <li>Python and C++ for Algorithm Development</li>
        <li>Real-time Control Systems</li>
        <li>Machine Learning for Object Detection</li>
    </ul>

    <h2>Project Gallery</h2>
    <div class="project-gallery">
        <img src="project2/euclidean_distances.png" alt="Robot Catching Object" class="gallery-image">
        <img src="project2/assemble sensor1.png" alt="Event-based Vision in Action" class="gallery-image">
        <img src="project2/control_points_image2.png" alt="High-Speed Object Detection" class="gallery-image">
    </div>

</div>

</body>
</html>
